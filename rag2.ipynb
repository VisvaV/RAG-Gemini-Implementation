{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7be0a22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\visva\\anaconda3\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from nbformat) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\visva\\appdata\\roaming\\python\\python312\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\visva\\appdata\\roaming\\python\\python312\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\visva\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\visva\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (310)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "039efce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Notebook is invalid: Notebook does not appear to be JSON: ''\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "try:\n",
    "    with open(\"rag2.ipynb\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    print(\"✅ Notebook is valid!\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Notebook is invalid:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0e8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\visva\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\visva\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\visva\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\visva\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\visva\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.169.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-generativeai) (2.40.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-generativeai) (2.11.4)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\visva\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\visva\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\visva\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\visva\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\visva\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.5/1.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.0/1.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Using cached torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.0/10.4 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.6/10.4 MB 2.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.1/10.4 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.1/10.4 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.7/10.4 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.9/10.4 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.7/10.4 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.0/10.4 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.5/10.4 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.8/10.4 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.6/10.4 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.1/10.4 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.169.0-py3-none-any.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.3 MB 2.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.3/13.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.1/13.3 MB 4.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.9/13.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.7/13.3 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.2/13.3 MB 3.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.2/13.3 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.0/13.3 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.6/13.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/13.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.1/13.3 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.9/13.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.4/13.3 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.2/13.3 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.0/13.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.5/13.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.1/13.3 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.8/13.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: uritemplate, sympy, safetensors, proto-plus, httplib2, torch, grpcio-status, google-auth-httplib2, google-api-core, transformers, google-api-python-client, sentence-transformers, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.169.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 safetensors-0.5.3 sentence-transformers-4.1.0 sympy-1.14.0 torch-2.7.0 transformers-4.51.3 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install sentence-transformers pandas scikit-learn google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389208c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   ID                 7000 non-null   int64 \n",
      " 1   Location           7000 non-null   object\n",
      " 2   Country            7000 non-null   object\n",
      " 3   Parking Available  7000 non-null   object\n",
      " 4   Weather            7000 non-null   object\n",
      " 5   Temperature        7000 non-null   int64 \n",
      " 6   Rain               5250 non-null   object\n",
      " 7   Wind Speed         7000 non-null   int64 \n",
      " 8   Description        7000 non-null   object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 492.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Parking Available</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Times Square</td>\n",
       "      <td>Canada</td>\n",
       "      <td>No</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>16</td>\n",
       "      <td>Light</td>\n",
       "      <td>6</td>\n",
       "      <td>Information about Times Square in Canada, weat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Berlin Wall</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>17</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>7</td>\n",
       "      <td>Information about Berlin Wall in Germany, weat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sydney Opera House</td>\n",
       "      <td>Australia</td>\n",
       "      <td>No</td>\n",
       "      <td>Windy</td>\n",
       "      <td>18</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>8</td>\n",
       "      <td>Information about Sydney Opera House in Austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taj Mahal</td>\n",
       "      <td>India</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>Information about Taj Mahal in India, weather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mount Fuji</td>\n",
       "      <td>Japan</td>\n",
       "      <td>No</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>20</td>\n",
       "      <td>Light</td>\n",
       "      <td>10</td>\n",
       "      <td>Information about Mount Fuji in Japan, weather...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID            Location    Country Parking Available Weather  Temperature  \\\n",
       "0   1        Times Square     Canada                No  Cloudy           16   \n",
       "1   2         Berlin Wall    Germany               Yes   Rainy           17   \n",
       "2   3  Sydney Opera House  Australia                No   Windy           18   \n",
       "3   4           Taj Mahal      India               Yes   Snowy           19   \n",
       "4   5          Mount Fuji      Japan                No   Foggy           20   \n",
       "\n",
       "       Rain  Wind Speed                                        Description  \n",
       "0     Light           6  Information about Times Square in Canada, weat...  \n",
       "1  Moderate           7  Information about Berlin Wall in Germany, weat...  \n",
       "2     Heavy           8  Information about Sydney Opera House in Austra...  \n",
       "3       NaN           9  Information about Taj Mahal in India, weather ...  \n",
       "4     Light          10  Information about Mount Fuji in Japan, weather...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"realistic_sample_data.csv\")\n",
    "\n",
    "# Show basic info and preview\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de497151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "df['combined_text'] = df[['Location', 'Country', 'Parking Available', 'Weather', 'Temperature', 'Rain', 'Wind Speed', 'Description']].astype(str).agg(' | '.join, axis=1)\n",
    "\n",
    "# Convert each text into a vector\n",
    "df['embedding'] = df['combined_text'].apply(lambda x: embedding_model.encode(str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d60138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to retrieve top-k most relevant chunks based on query\n",
    "def retrieve_top_k_chunks(query, df, k=5):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    similarities = cosine_similarity(query_embedding, df['embedding'].tolist())[0]\n",
    "    top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    return df.iloc[top_k_indices]['combined_text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb323041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine retrieved chunks + user query\n",
    "def build_rag_prompt(user_query, retrieved_chunks):\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "    prompt = f\"\"\"\n",
    "You are an expert assistant helping answer queries using provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{user_query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc77837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Setup Gemini\n",
    "genai.configure(api_key=\"AIzaSyAzbxmAPyzcR595QvjWsTHoIlprJmaKlJQ\")  # Replace with your actual key\n",
    "\n",
    "# Load the model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f23aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines the retrieved chunks with the user's query\n",
    "def build_rag_prompt(user_query, retrieved_chunks):\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "    prompt = f\"\"\"\n",
    "You are an expert assistant helping answer queries using the provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{user_query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45891d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001 -> ['generateMessage', 'countMessageTokens']\n",
      "models/text-bison-001 -> ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "models/embedding-gecko-001 -> ['embedText', 'countTextTokens']\n",
      "models/gemini-1.0-pro-vision-latest -> ['generateContent', 'countTokens']\n",
      "models/gemini-pro-vision -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-latest -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-pro-001 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro-002 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-pro -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-latest -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-001 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-001-tuning -> ['generateContent', 'countTokens', 'createTunedModel']\n",
      "models/gemini-1.5-flash -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-002 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-1.5-flash-8b -> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-001 -> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-latest -> ['createCachedContent', 'generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0827 -> ['generateContent', 'countTokens']\n",
      "models/gemini-1.5-flash-8b-exp-0924 -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-pro-exp-03-25 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.5-pro-preview-03-25 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.5-flash-preview-04-17 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.5-flash-preview-04-17-thinking -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.5-pro-preview-05-06 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-exp -> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-001 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-exp-image-generation -> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-lite -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-preview-image-generation -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-lite-preview -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-pro-exp -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-pro-exp-02-05 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-exp-1206 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-thinking-exp -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 -> ['generateContent', 'countTokens', 'createCachedContent']\n",
      "models/learnlm-1.5-pro-experimental -> ['generateContent', 'countTokens']\n",
      "models/learnlm-2.0-flash-experimental -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it -> ['generateContent', 'countTokens']\n",
      "models/embedding-001 -> ['embedContent']\n",
      "models/text-embedding-004 -> ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 -> ['embedContent', 'countTextTokens']\n",
      "models/gemini-embedding-exp -> ['embedContent', 'countTextTokens']\n",
      "models/aqa -> ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 -> ['predict']\n",
      "models/gemini-2.0-flash-live-001 -> ['bidiGenerateContent', 'countTokens']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Set your API key\n",
    "genai.configure(api_key=\"AIzaSyAzbxmAPyzcR595QvjWsTHoIlprJmaKlJQ\")\n",
    "\n",
    "# List available models to check which ones are allowed\n",
    "for m in genai.list_models():\n",
    "    print(m.name, \"->\", m.supported_generation_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42e6b7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Gemini Response:\n",
      " No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: User query\n",
    "user_query = \"Does Berlin Wall have Parking Available?\"\n",
    "\n",
    "# Step 2: Retrieve relevant context\n",
    "top_chunks = retrieve_top_k_chunks(user_query, df)\n",
    "\n",
    "# Step 3: Compose final prompt\n",
    "final_prompt = build_rag_prompt(user_query, top_chunks)\n",
    "\n",
    "# Step 4: Generate response\n",
    "response = model.generate_content(final_prompt)\n",
    "print(\"🧠 Gemini Response:\\n\", response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
